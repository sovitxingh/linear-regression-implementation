{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ff0cae-de9e-4afb-9d11-182ba0f268f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Adding src directory to the system path\n",
    "current_dir = os.getcwd()\n",
    "src_dir = os.path.join(current_dir, '..', 'src')\n",
    "sys.path.insert(0, os.path.abspath(src_dir))\n",
    "\n",
    "from utils import z_score_normalize\n",
    "from logistic_regressor import compute_logistic_cost, compute_logistic_gradients, logistic_gradient_descent, evaluate_model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e0269-2164-4598-abc9-2b6d43d9f40e",
   "metadata": {},
   "source": [
    "# Logistic Regression with L2 Regularization\n",
    "\n",
    "### Introduction\n",
    "This includes the documentation of the logistic regression model with L2 regularization implemented in this notebook.\n",
    "\n",
    "### Cost function\n",
    "The cost function used for logistic regression is\n",
    "$$\n",
    "J(\\vec{w}, b) = -\\frac{1}{m} \\sum_{i=0}^{m-1} \\left[ y^{(i)} \\log \\left( f_{\\vec{w}, b} (\\vec{x}^{(i)}) \\right) + (1 - y^{(i)}) \\log \\left( 1 - f_{\\vec{w}, b} (\\vec{x}^{(i)}) \\right) \\right] + \\frac{\\lambda}{2m} \\sum_{j=0}^{n-1} w_{j} ^ 2\n",
    "$$\n",
    "where *m* is the number of training examples, *n* is the number of features, and \\\\(\\lambda\\\\) is the regularization parameter.\n",
    "\n",
    "Also, $$ f_{\\vec{w},b}(\\mathbf{x}^{(i)}) = sigmoid(\\vec{w} \\cdot \\mathbf{x}^{(i)} + b)  $$ \n",
    "\n",
    "### Gradient Descent Algorithm\n",
    "$$\\begin{align*}\n",
    "&\\text{repeat until convergence:} \\; \\lbrace \\\\\n",
    "&  \\; \\; \\;w_j = w_j -  \\alpha \\frac{\\partial J(\\vec{w},b)}{\\partial w_j}   \\; & \\text{for j := 0..n-1} \\\\ \n",
    "&  \\; \\; \\;  \\; \\;b = b -  \\alpha \\frac{\\partial J(\\vec{w},b)}{\\partial b} \\\\\n",
    "&\\rbrace\n",
    "\\end{align*}$$\n",
    "where \\\\(\\vec{w}, b\\\\) are updated simultaneously.\n",
    "\n",
    "The gradient is defined as:\n",
    "$$\n",
    "\\frac{\\partial J(\\vec{w}, b)}{\\partial w_{j}} = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left( f_{\\vec{w},b}(\\vec{x}^{(i)}) - y^{(i)} \\right) x_{j}^{(i)} + \\frac{\\lambda}{m}  w_{j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(w, b)}{\\partial b} = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left( f_{\\vec{w},b}(\\vec{x}^{(i)}) - y^{(i)} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de0de25-f872-4144-bf61-8439bd47d020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed cost: 1.0846660094499971\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "y = np.array([0, 1, 0])\n",
    "w = np.array([0.1, 0.2])\n",
    "b = 0.1\n",
    "lambda_ = 0.01\n",
    "\n",
    "cost = compute_logistic_cost(X, y, w, b, lambda_)\n",
    "print(\"Computed cost:\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454771fb-85c9-4643-bcbe-1280b1d48d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db: [0.17380013 0.32007508 0.10776313]\n",
      "Regularized dj_dw:\n",
      " 0.341798994972791\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X_tmp = np.random.rand(5,3)\n",
    "y_tmp = np.array([0,1,0,1,0])\n",
    "w_tmp = np.random.rand(X_tmp.shape[1])\n",
    "b_tmp = 0.5\n",
    "lambda_tmp = 0.7\n",
    "dj_db_tmp, dj_dw_tmp =  compute_logistic_gradients(X_tmp, y_tmp, w_tmp, b_tmp, lambda_tmp)\n",
    "\n",
    "print(f\"dj_db: {dj_db_tmp}\", )\n",
    "print(f\"Regularized dj_dw:\\n {dj_dw_tmp.tolist()}\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093a57f-3248-4a3a-9392-8c13739527f5",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "```\n",
    "dj_db: 0.341798994972791\n",
    "Regularized dj_dw:\n",
    " [0.17380012933994293, 0.32007507881566943, 0.10776313396851499]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9edeb6f-aaf0-478f-b892-bb97eb940a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Weights: [-0.02736185  0.03851381  0.00059367  0.03306878 -0.00066092], Bias: -0.11145, Cost: 0.6426291071172929\n",
      "Iteration: 10000, Weights: [-2.06193018  2.7281239   0.02057885  2.45143232 -0.03232513], Bias: -5.379200920594113, Cost: 0.15162499022568948\n",
      "Iteration: 20000, Weights: [-2.06197816  2.72818766  0.02057887  2.45148852 -0.03232654], Bias: -5.379318318507932, Cost: 0.15162499018890885\n",
      "Iteration: 30000, Weights: [-2.06197816  2.72818767  0.02057887  2.45148852 -0.03232654], Bias: -5.379318327559568, Cost: 0.15162499018890885\n",
      "Iteration: 40000, Weights: [-2.06197816  2.72818767  0.02057887  2.45148852 -0.03232654], Bias: -5.379318327559914, Cost: 0.15162499018890882\n",
      "Iteration: 50000, Weights: [-2.06197816  2.72818767  0.02057887  2.45148852 -0.03232654], Bias: -5.379318327559914, Cost: 0.15162499018890882\n",
      "Iteration: 60000, Weights: [-2.06197816  2.72818767  0.02057887  2.45148852 -0.03232654], Bias: -5.379318327559914, Cost: 0.15162499018890882\n",
      "Iteration: 70000, Weights: [-2.06197816  2.72818767  0.02057887  2.45148852 -0.03232654], Bias: -5.379318327559914, Cost: 0.15162499018890882\n",
      "Iteration: 80000, Weights: [-2.06197816  2.72818767  0.02057887  2.45148852 -0.03232654], Bias: -5.379318327559914, Cost: 0.15162499018890882\n",
      "Iteration: 90000, Weights: [-2.06197816  2.72818767  0.02057887  2.45148852 -0.03232654], Bias: -5.379318327559914, Cost: 0.15162499018890882\n",
      "Optimized weights: [-2.06197816  2.72818767  0.02057887  2.45148852 -0.03232654]\n",
      "Optimized bias: -5.379318327559914\n",
      "Final cost: 0.15162499018890882\n"
     ]
    }
   ],
   "source": [
    "# Ensure the file path is correct and the file exists\n",
    "file_path = 'C:/GitHub/linear-logistic-regression-implementation/data/weather_forecast_data.csv'\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assign features and target values\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Convert labels to boolean (True for 'rain', False for 'no rain')\n",
    "y = np.array((y == 'rain').astype(int))  # Ensuring y is an integer array\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = z_score_normalize(X_train)\n",
    "X_test = z_score_normalize(X_test)\n",
    "\n",
    "# Initialize parameters\n",
    "m, n = X.shape\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0\n",
    "alpha = 0.3\n",
    "num_iters = 100000\n",
    "lambda_ = 0.01\n",
    "\n",
    "# Perform gradient descent\n",
    "w, b, J_history = logistic_gradient_descent(X_train, y_train, initial_w, initial_b, alpha, num_iters, lambda_)\n",
    "\n",
    "print(\"Optimized weights:\", w)\n",
    "print(\"Optimized bias:\", b)\n",
    "print(\"Final cost:\", J_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e07491-8d75-4be4-88fd-b268cfe61fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[426  17]\n",
      " [ 15  42]]\n",
      "Accuracy: 0.936\n",
      "Precision: 0.711864406779661\n",
      "Recall: 0.7368421052631579\n",
      "F1 Score: 0.7241379310344828\n",
      "Test Accuracy: 0.936\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on the training data\n",
    "accuracy = evaluate_model_performance(X_test, y_test, w, b)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43757339-4604-42c1-afcb-9a592c87d716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
