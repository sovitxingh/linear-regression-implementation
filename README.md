# Machine Learning Implementations from Scratch

## 📝 Description
This repository contains implementations of foundational machine learning concepts, inspired by the **Coursera Machine Learning Specialization** by Andrew Ng. Each algorithm is implemented from scratch in Python, focusing on deepening understanding and practical applications.

---

## 📂 Repository Structure
- `notebooks/`: Jupyter notebooks for each implementation.
- `data/`: Sample datasets used for training and testing.
- `src/`: Helper functions and reusable modules for the algorithms.
- `README.md`: Overview of the project and usage instructions.

---

## 🚀 Implementations
1. **Linear Regression**
   - Gradient descent optimization
   - L2 Regularization (Ridge Regression)
   - Feature scaling and engineering
2. **Logistic Regression**
   - Binary classification
   - Regularization to prevent overfitting
3. **Feature Scaling**
   - Min-max scaling
   - Standardization (Z-score normalization)

---

## 📊 Results
- Visualizations of training progress (loss vs. iterations).
- Comparison of performance with and without regularization.
- Insights from feature scaling on different datasets.

---

## 🔧 Technologies Used
- **Programming Language:** Python
- **Libraries:** NumPy, Matplotlib, Pandas
- **Environment:** Jupyter Notebook

---

## 📖 Usage
### 1. Clone the repository:
```bash
https://github.com/sovitxingh/linear-regression-implementation.git
