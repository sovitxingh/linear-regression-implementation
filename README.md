# Machine Learning Implementations from Scratch

## ğŸ“ Description
This repository contains implementations of foundational machine learning concepts, inspired by the **Coursera Machine Learning Specialization** by Andrew Ng. Each algorithm is implemented from scratch in Python, focusing on deepening understanding and practical applications.

---

## ğŸ“‚ Repository Structure
- `notebooks/`: Jupyter notebooks for each implementation.
- `data/`: Sample datasets used for training and testing.
- `src/`: Helper functions and reusable modules for the algorithms.
- `README.md`: Overview of the project and usage instructions.

---

## ğŸš€ Implementations
1. **Linear Regression**
   - Gradient descent optimization
   - L2 Regularization (Ridge Regression)
   - Feature scaling and engineering
2. **Logistic Regression**
   - Binary classification
   - Regularization to prevent overfitting
3. **Feature Scaling**
   - Min-max scaling
   - Standardization (Z-score normalization)

---

## ğŸ“Š Results
- Visualizations of training progress (loss vs. iterations).
- Comparison of performance with and without regularization.
- Insights from feature scaling on different datasets.

---

## ğŸ”§ Technologies Used
- **Programming Language:** Python
- **Libraries:** NumPy, Matplotlib, Pandas
- **Environment:** Jupyter Notebook

---

## ğŸ“– Usage
### 1. Clone the repository:
```bash
https://github.com/sovitxingh/linear-regression-implementation.git
